2025-03-28 05:44:50,270 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[03/28/2025-05:44:50] [TRT-LLM] [I] Preparing to run throughput benchmark...
[03/28/2025-05:44:52] [TRT-LLM] [I] 
===========================================================
= DATASET DETAILS
===========================================================
Dataset Path:         /userdata/dataset.txt
Number of Sequences:  8192

-- Percentiles statistics ---------------------------------

        Input              Output           Seq. Length
-----------------------------------------------------------
MIN:  1000.0000          1000.0000          2000.0000
MAX:  1000.0000          1000.0000          2000.0000
AVG:  1000.0000          1000.0000          2000.0000
P50:  1000.0000          1000.0000          2000.0000
P90:  1000.0000          1000.0000          2000.0000
P95:  1000.0000          1000.0000          2000.0000
P99:  1000.0000          1000.0000          2000.0000
===========================================================

[03/28/2025-05:44:52] [TRT-LLM] [I] Use user-provided max batch size and max num tokens.
[03/28/2025-05:44:52] [TRT-LLM] [I] Setting PyTorch max sequence length to 2000
[03/28/2025-05:44:52] [TRT-LLM] [I] Setting up throughput benchmark.
[03/28/2025-05:44:52] [TRT-LLM] [W] Overriding pytorch_backend_config because it's specified in /userdata/deepseek-test/trt-llm-R1/extra-llm-api-config.yml
[03/28/2025-05:44:52] [TRT-LLM] [W] Using default gpus_per_node: 8
[03/28/2025-05:44:52] [TRT-LLM] [I] Compute capability: (10, 0)
[03/28/2025-05:44:52] [TRT-LLM] [I] SM count: 148
[03/28/2025-05:44:52] [TRT-LLM] [I] SM clock: 1965 MHz
[03/28/2025-05:44:52] [TRT-LLM] [I] int4 TFLOPS: 0
[03/28/2025-05:44:52] [TRT-LLM] [I] int8 TFLOPS: 0
[03/28/2025-05:44:52] [TRT-LLM] [I] fp8 TFLOPS: 0
[03/28/2025-05:44:52] [TRT-LLM] [I] float16 TFLOPS: 0
[03/28/2025-05:44:52] [TRT-LLM] [I] bfloat16 TFLOPS: 0
[03/28/2025-05:44:52] [TRT-LLM] [I] float32 TFLOPS: 0
[03/28/2025-05:44:52] [TRT-LLM] [I] Total Memory: 179 GiB
[03/28/2025-05:44:52] [TRT-LLM] [I] Memory clock: 3996 MHz
[03/28/2025-05:44:52] [TRT-LLM] [I] Memory bus width: 7680
[03/28/2025-05:44:52] [TRT-LLM] [I] Memory bandwidth: 7672 GB/s
[03/28/2025-05:44:52] [TRT-LLM] [I] NVLink is active: True
[03/28/2025-05:44:52] [TRT-LLM] [I] NVLink version: 4
[03/28/2025-05:44:52] [TRT-LLM] [I] NVLink bandwidth: 450 GB/s
[03/28/2025-05:44:52] [TRT-LLM] [W] Conflict detected in LlmArgs build_config.max_batch_size (2048) != max_batch_size (161).The 'max_batch_size' specified in LlmArgs is ignored at engine build and will override at runtime.
[03/28/2025-05:44:52] [TRT-LLM] [W] Conflict detected in LlmArgs build_config.max_num_tokens (8192) != max_batch_size (1160).The 'max_num_tokens' specified in LlmArgs is ignored at engine build and will override at runtime.
[03/28/2025-05:44:52] [TRT-LLM] [I] Set nccl_plugin to None.
[03/28/2025-05:44:52] [TRT-LLM] [I] start MpiSession with 8 workers
[03/28/2025-05:44:52] [TRT-LLM] [I] PyTorchConfig(extra_resource_managers={}, use_cuda_graph=False, cuda_graph_batch_sizes=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 64, 128], cuda_graph_max_batch_size=128, cuda_graph_padding_enabled=False, enable_overlap_scheduler=False, attn_backend='TRTLLM', mixed_decoder=False, enable_trtllm_decoder=False, kv_cache_dtype='auto', use_kv_cache=True, enable_iter_perf_stats=False, print_iter_log=False, torch_compile_enabled=False, torch_compile_fullgraph=False, torch_compile_inductor_enabled=False, torch_compile_enable_userbuffers=True, autotuner_enabled=True, enable_layerwise_nvtx_marker=False, load_format=<LoadFormat.AUTO: 0>)
[33;20mUsing MpiPoolSession to spawn MPI processes
[0m2025-03-28 05:45:09,992 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-28 05:45:09,992 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-28 05:45:09,997 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-28 05:45:10,007 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-28 05:45:10,014 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-28 05:45:10,019 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-28 05:45:10,026 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
2025-03-28 05:45:10,054 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM] TensorRT-LLM version: 0.19.0.dev2025032500
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] Refreshed the MPI local session
[TensorRT-LLM][INFO] Refreshed the MPI local session
[03/28/2025-05:45:12] [TRT-LLM] [I] Validating KV Cache config against kv_cache_dtype="auto"
[03/28/2025-05:45:12] [TRT-LLM] [I] KV cache quantization set to "auto". Using checkpoint KV quantization.
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00002-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00023-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00078-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00026-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00041-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00140-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00141-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00163-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00071-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00074-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00063-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00126-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00007-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00149-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00120-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00012-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00079-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00040-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00103-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00138-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00017-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00102-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00105-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00039-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00092-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00114-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00085-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00100-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00121-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00107-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00153-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00101-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00067-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00098-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00087-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00122-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00062-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00059-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00108-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00021-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00019-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00084-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00070-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00080-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00036-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00158-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00001-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00104-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00069-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00015-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00072-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00043-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00033-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00128-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00088-of-000163.safetensors
[03/28/2025-05:45:16] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00010-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00129-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00147-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00089-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00116-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00035-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00154-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00146-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00139-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00155-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00097-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00066-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00064-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00160-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00008-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00025-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00034-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00028-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00077-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00152-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00048-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00118-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00135-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00024-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00009-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00157-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00011-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00093-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00082-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00030-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00099-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00148-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00095-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00091-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00013-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00111-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00094-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00073-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00058-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00049-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00052-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00115-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00142-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00150-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00145-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00055-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00131-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00136-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00076-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00083-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00047-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00144-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00127-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00005-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00132-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00050-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00044-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00014-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00004-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00117-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00081-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00075-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00027-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00022-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00113-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00162-of-000163.safetensors
[03/28/2025-05:45:17] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00046-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00109-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00053-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00090-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00130-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00016-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00156-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00054-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00119-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00134-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00096-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00137-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00086-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00018-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00133-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00143-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00003-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00112-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00042-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00106-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00051-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00045-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00057-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00006-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00125-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00029-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00124-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00123-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00056-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00020-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00151-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00031-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00068-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00061-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00159-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00065-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00037-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00161-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00032-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00110-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00038-of-000163.safetensors
[03/28/2025-05:45:18] [TRT-LLM] [I] Loading /userdata/llms/deepseek-ai/DeepSeek-R1/model-00060-of-000163.safetensors
Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 0/1524 [00:00<?, ?it/s]Loading weights:   0%|          | 3/1524 [00:00<02:51,  8.85it/s]Loading weights:   0%|          | 3/1524 [00:00<02:52,  8.84it/s]Loading weights:   0%|          | 3/1524 [00:00<02:52,  8.84it/s]Loading weights:   0%|          | 3/1524 [00:00<02:52,  8.83it/s]Loading weights:   0%|          | 3/1524 [00:00<02:52,  8.82it/s]Loading weights:   0%|          | 3/1524 [00:00<02:52,  8.82it/s]Loading weights:   0%|          | 3/1524 [00:00<02:57,  8.58it/s]Loading weights:   0%|          | 3/1524 [00:00<02:57,  8.57it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.61it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.58it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.47it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.50it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.46it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.38it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.41it/s]Loading weights:   1%|▏         | 21/1524 [00:00<00:26, 57.42it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 102.57it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 102.61it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 102.24it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 102.07it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 102.14it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 101.92it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 100.03it/s]Loading weights:   3%|▎         | 43/1524 [00:00<00:14, 100.04it/s]Loading weights:   4%|▍         | 65/1524 [00:00<00:10, 134.38it/s]Loading weights:   4%|▍         | 65/1524 [00:00<00:10, 133.89it/s]Loading weights:   4%|▍         | 65/1524 [00:00<00:10, 133.55it/s]Loading weights:   4%|▍         | 65/1524 [00:00<00:10, 133.85it/s]Loading weights:   4%|▍         | 65/1524 [00:00<00:10, 133.23it/s]Loading weights:   4%|▍         | 65/1524 [00:00<00:10, 133.29it/s]Loading weights:   4%|▍         | 67/1524 [00:00<00:10, 137.65it/s]Loading weights:   4%|▍         | 67/1524 [00:00<00:10, 137.11it/s]Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 70.51it/s] Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 70.38it/s] Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 69.70it/s] Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 69.63it/s] Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 69.43it/s] Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 69.37it/s] Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 68.94it/s] Loading weights:   6%|▌         | 86/1524 [00:01<00:20, 69.06it/s] Loading weights:   7%|▋         | 111/1524 [00:01<00:23, 60.91it/s]Loading weights:   7%|▋         | 111/1524 [00:01<00:23, 60.88it/s]Loading weights:   7%|▋         | 111/1524 [00:01<00:24, 57.61it/s]Loading weights:   7%|▋         | 111/1524 [00:01<00:24, 57.66it/s]Loading weights:   7%|▋         | 111/1524 [00:01<00:24, 56.98it/s]Loading weights:   7%|▋         | 111/1524 [00:01<00:24, 56.89it/s]Loading weights:   7%|▋         | 111/1524 [00:01<00:25, 56.33it/s]Loading weights:   7%|▋         | 111/1524 [00:01<00:25, 56.44it/s]Loading weights:   9%|▉         | 135/1524 [00:01<00:16, 82.34it/s]Loading weights:   9%|▉         | 135/1524 [00:01<00:16, 82.30it/s]Loading weights:  10%|▉         | 150/1524 [00:02<00:23, 58.80it/s]Loading weights:  10%|▉         | 150/1524 [00:02<00:23, 58.81it/s]Loading weights:   9%|▉         | 136/1524 [00:02<00:26, 52.46it/s]Loading weights:   9%|▉         | 136/1524 [00:02<00:26, 52.49it/s]Loading weights:   9%|▉         | 136/1524 [00:02<00:26, 51.86it/s]Loading weights:   9%|▉         | 136/1524 [00:02<00:26, 51.79it/s]Loading weights:   9%|▉         | 136/1524 [00:02<00:26, 51.41it/s]Loading weights:   9%|▉         | 136/1524 [00:02<00:26, 51.49it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:29, 45.96it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:29, 45.97it/s]Loading weights:  12%|█▏        | 185/1524 [00:02<00:20, 66.44it/s]Loading weights:  12%|█▏        | 185/1524 [00:02<00:20, 66.43it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:27, 49.74it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:27, 49.75it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:27, 49.16it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:27, 49.11it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:28, 48.64it/s]Loading weights:  11%|█         | 161/1524 [00:02<00:27, 48.69it/s]Loading weights:  12%|█▏        | 185/1524 [00:02<00:20, 66.56it/s]Loading weights:  13%|█▎        | 198/1524 [00:03<00:25, 51.67it/s]Loading weights:  13%|█▎        | 198/1524 [00:03<00:25, 51.67it/s]Loading weights:  12%|█▏        | 186/1524 [00:03<00:27, 48.41it/s]Loading weights:  12%|█▏        | 186/1524 [00:03<00:28, 47.76it/s]Loading weights:  12%|█▏        | 186/1524 [00:03<00:28, 47.73it/s]Loading weights:  13%|█▎        | 198/1524 [00:03<00:25, 51.20it/s]Loading weights:  12%|█▏        | 186/1524 [00:03<00:28, 47.06it/s]Loading weights:  12%|█▏        | 186/1524 [00:03<00:28, 47.10it/s]Loading weights:  14%|█▍        | 211/1524 [00:03<00:30, 43.51it/s]Loading weights:  14%|█▍        | 211/1524 [00:03<00:30, 43.51it/s]Loading weights:  15%|█▌        | 235/1524 [00:03<00:20, 64.21it/s]Loading weights:  15%|█▌        | 235/1524 [00:03<00:20, 64.22it/s]Loading weights:  14%|█▍        | 211/1524 [00:03<00:27, 47.31it/s]Loading weights:  14%|█▍        | 211/1524 [00:03<00:31, 41.97it/s]Loading weights:  14%|█▍        | 211/1524 [00:03<00:28, 46.74it/s]Loading weights:  14%|█▍        | 211/1524 [00:03<00:28, 46.72it/s]Loading weights:  14%|█▍        | 211/1524 [00:04<00:28, 46.02it/s]Loading weights:  14%|█▍        | 211/1524 [00:04<00:28, 46.05it/s]Loading weights:  15%|█▌        | 235/1524 [00:04<00:21, 60.99it/s]Loading weights:  15%|█▌        | 235/1524 [00:04<00:21, 61.00it/s]Loading weights:  16%|█▋        | 248/1524 [00:04<00:25, 50.75it/s]Loading weights:  16%|█▋        | 248/1524 [00:04<00:25, 50.74it/s]Loading weights:  15%|█▌        | 236/1524 [00:04<00:29, 44.29it/s]Loading weights:  15%|█▌        | 236/1524 [00:04<00:26, 47.74it/s]Loading weights:  15%|█▌        | 236/1524 [00:04<00:26, 47.91it/s]Loading weights:  15%|█▌        | 236/1524 [00:04<00:26, 47.92it/s]Loading weights:  17%|█▋        | 260/1524 [00:04<00:20, 61.26it/s]Loading weights:  17%|█▋        | 260/1524 [00:04<00:20, 62.54it/s]Loading weights:  16%|█▌        | 247/1524 [00:04<00:26, 47.30it/s]Loading weights:  16%|█▌        | 247/1524 [00:04<00:27, 47.29it/s]Loading weights:  17%|█▋        | 261/1524 [00:04<00:29, 42.74it/s]Loading weights:  17%|█▋        | 261/1524 [00:04<00:29, 42.75it/s]Loading weights:  19%|█▊        | 285/1524 [00:04<00:19, 63.33it/s]Loading weights:  19%|█▊        | 285/1524 [00:04<00:19, 63.32it/s]Loading weights:  17%|█▋        | 261/1524 [00:05<00:26, 46.85it/s]Loading weights:  17%|█▋        | 261/1524 [00:05<00:26, 46.84it/s]Loading weights:  18%|█▊        | 271/1524 [00:05<00:25, 48.21it/s]Loading weights:  18%|█▊        | 272/1524 [00:05<00:26, 46.98it/s]Loading weights:  17%|█▋        | 261/1524 [00:05<00:31, 40.09it/s]Loading weights:  17%|█▋        | 261/1524 [00:05<00:31, 40.11it/s]Loading weights:  20%|█▉        | 298/1524 [00:05<00:24, 49.83it/s]Loading weights:  20%|█▉        | 298/1524 [00:05<00:24, 49.83it/s]Loading weights:  19%|█▉        | 286/1524 [00:05<00:29, 41.61it/s]Loading weights:  19%|█▉        | 286/1524 [00:05<00:31, 39.87it/s]Loading weights:  19%|█▉        | 286/1524 [00:05<00:26, 46.17it/s]Loading weights:  19%|█▉        | 286/1524 [00:05<00:26, 46.18it/s]Loading weights:  20%|██        | 310/1524 [00:05<00:20, 58.06it/s]Loading weights:  20%|██        | 311/1524 [00:05<00:28, 42.17it/s]Loading weights:  20%|██        | 311/1524 [00:05<00:28, 42.17it/s]Loading weights:  19%|█▉        | 286/1524 [00:05<00:29, 41.58it/s]Loading weights:  19%|█▉        | 286/1524 [00:05<00:29, 41.59it/s]Loading weights:  22%|██▏       | 335/1524 [00:05<00:19, 62.40it/s]Loading weights:  22%|██▏       | 335/1524 [00:05<00:19, 62.40it/s]Loading weights:  20%|██        | 311/1524 [00:06<00:28, 42.84it/s]Loading weights:  20%|██        | 311/1524 [00:06<00:26, 45.76it/s]Loading weights:  20%|██        | 311/1524 [00:06<00:26, 45.77it/s]Loading weights:  21%|██        | 323/1524 [00:06<00:26, 45.43it/s]Loading weights:  23%|██▎       | 348/1524 [00:06<00:24, 48.58it/s]Loading weights:  23%|██▎       | 348/1524 [00:06<00:24, 48.58it/s]Loading weights:  20%|██        | 311/1524 [00:06<00:28, 42.46it/s]Loading weights:  20%|██        | 311/1524 [00:06<00:28, 42.47it/s]Loading weights:  22%|██▏       | 336/1524 [00:06<00:25, 47.20it/s]Loading weights:  22%|██▏       | 336/1524 [00:06<00:25, 47.20it/s]Loading weights:  22%|██▏       | 336/1524 [00:06<00:27, 43.94it/s]Loading weights:  22%|██▏       | 336/1524 [00:06<00:30, 38.60it/s]Loading weights:  24%|██▎       | 361/1524 [00:06<00:29, 39.68it/s]Loading weights:  24%|██▎       | 361/1524 [00:06<00:29, 39.68it/s]Loading weights:  25%|██▌       | 385/1524 [00:06<00:19, 59.07it/s]Loading weights:  25%|██▌       | 385/1524 [00:06<00:19, 59.05it/s]Loading weights:  22%|██▏       | 336/1524 [00:06<00:27, 43.16it/s]Loading weights:  22%|██▏       | 336/1524 [00:06<00:27, 43.16it/s]Loading weights:  24%|██▎       | 361/1524 [00:07<00:25, 46.36it/s]Loading weights:  24%|██▎       | 361/1524 [00:07<00:25, 46.35it/s]Loading weights:  24%|██▎       | 361/1524 [00:07<00:26, 44.52it/s]Loading weights:  24%|██▎       | 361/1524 [00:07<00:28, 41.18it/s]Loading weights:  25%|██▌       | 385/1524 [00:07<00:18, 60.69it/s]Loading weights:  25%|██▌       | 385/1524 [00:07<00:19, 58.31it/s]Loading weights:  26%|██▌       | 397/1524 [00:07<00:24, 45.89it/s]Loading weights:  26%|██▌       | 397/1524 [00:07<00:24, 45.87it/s]Loading weights:  24%|██▎       | 361/1524 [00:07<00:26, 43.56it/s]Loading weights:  24%|██▎       | 361/1524 [00:07<00:26, 43.56it/s]Loading weights:  25%|██▌       | 385/1524 [00:07<00:19, 58.07it/s]Loading weights:  25%|██▌       | 385/1524 [00:07<00:19, 58.07it/s]Loading weights:  25%|██▌       | 386/1524 [00:07<00:23, 47.67it/s]Loading weights:  26%|██▌       | 396/1524 [00:07<00:22, 49.65it/s]Loading weights:  25%|██▌       | 386/1524 [00:07<00:25, 44.86it/s]Loading weights:  26%|██▌       | 397/1524 [00:07<00:24, 45.55it/s]Loading weights:  27%|██▋       | 411/1524 [00:07<00:28, 38.50it/s]Loading weights:  27%|██▋       | 411/1524 [00:07<00:28, 38.50it/s]Loading weights:  29%|██▊       | 435/1524 [00:07<00:18, 57.60it/s]Loading weights:  29%|██▊       | 435/1524 [00:07<00:18, 57.60it/s]Loading weights:  26%|██▌       | 396/1524 [00:08<00:24, 45.34it/s]Loading weights:  26%|██▌       | 396/1524 [00:08<00:24, 45.34it/s]Loading weights:  27%|██▋       | 411/1524 [00:08<00:26, 42.39it/s]Loading weights:  27%|██▋       | 411/1524 [00:08<00:23, 46.69it/s]Loading weights:  27%|██▋       | 411/1524 [00:08<00:24, 45.15it/s]Loading weights:  27%|██▋       | 411/1524 [00:08<00:28, 39.25it/s]Loading weights:  29%|██▉       | 447/1524 [00:08<00:24, 43.83it/s]Loading weights:  29%|██▉       | 447/1524 [00:08<00:24, 43.81it/s]Loading weights:  27%|██▋       | 411/1524 [00:08<00:28, 39.53it/s]Loading weights:  27%|██▋       | 411/1524 [00:08<00:28, 39.53it/s]Loading weights:  29%|██▊       | 436/1524 [00:08<00:25, 43.17it/s]Loading weights:  29%|██▊       | 436/1524 [00:08<00:23, 46.05it/s]Loading weights:  29%|██▊       | 436/1524 [00:08<00:24, 45.21it/s]Loading weights:  29%|██▊       | 436/1524 [00:08<00:26, 41.43it/s]Loading weights:  30%|███       | 461/1524 [00:08<00:26, 39.65it/s]Loading weights:  30%|███       | 461/1524 [00:08<00:26, 39.65it/s]Loading weights:  32%|███▏      | 485/1524 [00:09<00:17, 59.02it/s]Loading weights:  32%|███▏      | 485/1524 [00:09<00:17, 59.03it/s]Loading weights:  29%|██▊       | 436/1524 [00:09<00:26, 41.07it/s]Loading weights:  29%|██▊       | 436/1524 [00:09<00:26, 41.07it/s]Loading weights:  30%|███       | 461/1524 [00:09<00:24, 43.54it/s]Loading weights:  30%|███       | 461/1524 [00:09<00:23, 45.50it/s]Loading weights:  30%|███       | 461/1524 [00:09<00:23, 45.25it/s]Loading weights:  30%|███       | 461/1524 [00:09<00:24, 42.75it/s]Loading weights:  33%|███▎      | 497/1524 [00:09<00:21, 47.07it/s]Loading weights:  33%|███▎      | 497/1524 [00:09<00:21, 47.07it/s]Loading weights:  30%|███       | 461/1524 [00:09<00:25, 42.15it/s]Loading weights:  30%|███       | 461/1524 [00:09<00:25, 42.15it/s]Loading weights:  32%|███▏      | 485/1524 [00:09<00:18, 57.30it/s]Loading weights:  32%|███▏      | 485/1524 [00:09<00:18, 57.30it/s]Loading weights:  34%|███▎      | 511/1524 [00:09<00:24, 41.30it/s]Loading weights:  34%|███▎      | 511/1524 [00:09<00:24, 41.30it/s]Loading weights:  32%|███▏      | 486/1524 [00:09<00:22, 45.24it/s]Loading weights:  32%|███▏      | 486/1524 [00:09<00:23, 43.90it/s]Loading weights:  32%|███▏      | 486/1524 [00:09<00:22, 45.26it/s]Loading weights:  32%|███▏      | 486/1524 [00:09<00:23, 43.58it/s]Loading weights:  35%|███▌      | 535/1524 [00:09<00:16, 61.37it/s]Loading weights:  35%|███▌      | 535/1524 [00:09<00:16, 61.38it/s]Loading weights:  33%|███▎      | 496/1524 [00:10<00:23, 44.57it/s]Loading weights:  33%|███▎      | 496/1524 [00:10<00:23, 44.55it/s]Loading weights:  36%|███▌      | 548/1524 [00:10<00:20, 48.18it/s]Loading weights:  36%|███▌      | 548/1524 [00:10<00:20, 48.17it/s]Loading weights:  34%|███▎      | 511/1524 [00:10<00:22, 45.08it/s]Loading weights:  34%|███▎      | 511/1524 [00:10<00:22, 44.15it/s]Loading weights:  34%|███▎      | 511/1524 [00:10<00:22, 45.41it/s]Loading weights:  34%|███▎      | 511/1524 [00:10<00:22, 44.26it/s]Loading weights:  34%|███▎      | 511/1524 [00:10<00:25, 39.05it/s]Loading weights:  34%|███▎      | 511/1524 [00:10<00:25, 39.05it/s]Loading weights:  37%|███▋      | 561/1524 [00:10<00:23, 41.56it/s]Loading weights:  37%|███▋      | 561/1524 [00:10<00:23, 41.56it/s]Loading weights:  35%|███▌      | 535/1524 [00:10<00:17, 56.31it/s]Loading weights:  35%|███▌      | 535/1524 [00:10<00:17, 56.31it/s]Loading weights:  38%|███▊      | 585/1524 [00:11<00:15, 61.81it/s]Loading weights:  38%|███▊      | 585/1524 [00:11<00:15, 61.80it/s]Loading weights:  35%|███▌      | 536/1524 [00:11<00:21, 45.46it/s]Loading weights:  35%|███▌      | 536/1524 [00:11<00:22, 44.67it/s]Loading weights:  35%|███▌      | 536/1524 [00:11<00:22, 44.88it/s]Loading weights:  35%|███▌      | 536/1524 [00:11<00:22, 44.24it/s]Loading weights:  36%|███▌      | 547/1524 [00:11<00:22, 43.85it/s]Loading weights:  36%|███▌      | 547/1524 [00:11<00:22, 43.84it/s]Loading weights:  39%|███▉      | 598/1524 [00:11<00:19, 48.11it/s]Loading weights:  39%|███▉      | 598/1524 [00:11<00:19, 48.11it/s]Loading weights:  37%|███▋      | 561/1524 [00:11<00:21, 45.56it/s]Loading weights:  37%|███▋      | 561/1524 [00:11<00:20, 46.00it/s]Loading weights:  37%|███▋      | 561/1524 [00:11<00:21, 45.36it/s]Loading weights:  37%|███▋      | 561/1524 [00:11<00:21, 44.81it/s]Loading weights:  37%|███▋      | 561/1524 [00:11<00:25, 37.69it/s]Loading weights:  37%|███▋      | 561/1524 [00:11<00:25, 37.68it/s]Loading weights:  40%|████      | 611/1524 [00:11<00:23, 39.11it/s]Loading weights:  40%|████      | 611/1524 [00:11<00:23, 39.11it/s]Loading weights:  38%|███▊      | 585/1524 [00:12<00:16, 55.84it/s]Loading weights:  38%|███▊      | 585/1524 [00:12<00:16, 55.84it/s]Loading weights:  42%|████▏     | 635/1524 [00:12<00:15, 58.69it/s]Loading weights:  42%|████▏     | 635/1524 [00:12<00:15, 58.68it/s]Loading weights:  38%|███▊      | 586/1524 [00:12<00:20, 45.26it/s]Loading weights:  38%|███▊      | 586/1524 [00:12<00:20, 45.57it/s]Loading weights:  38%|███▊      | 586/1524 [00:12<00:20, 45.37it/s]Loading weights:  38%|███▊      | 586/1524 [00:12<00:20, 44.99it/s]Loading weights:  39%|███▉      | 598/1524 [00:12<00:21, 43.71it/s]Loading weights:  39%|███▉      | 598/1524 [00:12<00:21, 43.71it/s]Loading weights:  43%|████▎     | 648/1524 [00:12<00:19, 44.91it/s]Loading weights:  43%|████▎     | 648/1524 [00:12<00:19, 44.91it/s]Loading weights:  40%|████      | 611/1524 [00:12<00:19, 46.87it/s]Loading weights:  40%|████      | 611/1524 [00:12<00:19, 46.61it/s]Loading weights:  40%|████      | 611/1524 [00:12<00:19, 46.01it/s]Loading weights:  40%|████      | 611/1524 [00:12<00:19, 45.80it/s]Loading weights:  42%|████▏     | 635/1524 [00:12<00:14, 61.17it/s]Loading weights:  43%|████▎     | 661/1524 [00:13<00:22, 38.48it/s]Loading weights:  43%|████▎     | 661/1524 [00:13<00:22, 38.48it/s]Loading weights:  40%|████      | 611/1524 [00:13<00:24, 36.84it/s]Loading weights:  40%|████      | 611/1524 [00:13<00:24, 36.84it/s]Loading weights:  45%|████▍     | 685/1524 [00:13<00:14, 57.79it/s]Loading weights:  45%|████▍     | 685/1524 [00:13<00:14, 57.79it/s]Loading weights:  42%|████▏     | 635/1524 [00:13<00:16, 55.24it/s]Loading weights:  42%|████▏     | 635/1524 [00:13<00:16, 55.24it/s]Loading weights:  42%|████▏     | 636/1524 [00:13<00:19, 46.33it/s]Loading weights:  42%|████▏     | 636/1524 [00:13<00:19, 45.79it/s]Loading weights:  42%|████▏     | 636/1524 [00:13<00:19, 45.65it/s]Loading weights:  42%|████▏     | 646/1524 [00:13<00:18, 47.57it/s]Loading weights:  46%|████▌     | 698/1524 [00:13<00:18, 44.97it/s]Loading weights:  46%|████▌     | 698/1524 [00:13<00:18, 44.97it/s]Loading weights:  43%|████▎     | 648/1524 [00:13<00:20, 43.00it/s]Loading weights:  43%|████▎     | 648/1524 [00:13<00:20, 43.00it/s]Loading weights:  43%|████▎     | 661/1524 [00:13<00:18, 46.07it/s]Loading weights:  43%|████▎     | 661/1524 [00:13<00:20, 41.52it/s]Loading weights:  43%|████▎     | 661/1524 [00:13<00:18, 45.45it/s]Loading weights:  43%|████▎     | 661/1524 [00:13<00:19, 45.34it/s]Loading weights:  47%|████▋     | 711/1524 [00:14<00:21, 37.53it/s]Loading weights:  47%|████▋     | 711/1524 [00:14<00:21, 37.53it/s]Loading weights:  43%|████▎     | 661/1524 [00:14<00:23, 36.53it/s]Loading weights:  43%|████▎     | 661/1524 [00:14<00:23, 36.53it/s]Loading weights:  48%|████▊     | 735/1524 [00:14<00:13, 56.61it/s]Loading weights:  45%|████▌     | 686/1524 [00:14<00:18, 45.87it/s]Loading weights:  45%|████▌     | 686/1524 [00:14<00:19, 42.86it/s]Loading weights:  45%|████▌     | 686/1524 [00:14<00:18, 45.24it/s]Loading weights:  45%|████▌     | 686/1524 [00:14<00:18, 45.31it/s]Loading weights:  48%|████▊     | 736/1524 [00:14<00:19, 40.75it/s]Loading weights:  49%|████▉     | 748/1524 [00:14<00:17, 44.83it/s]Loading weights:  45%|████▌     | 686/1524 [00:14<00:21, 39.30it/s]Loading weights:  45%|████▌     | 686/1524 [00:14<00:21, 39.30it/s]Loading weights:  47%|████▋     | 711/1524 [00:14<00:17, 45.71it/s]Loading weights:  47%|████▋     | 711/1524 [00:14<00:18, 43.68it/s]Loading weights:  47%|████▋     | 711/1524 [00:14<00:18, 45.16it/s]Loading weights:  47%|████▋     | 711/1524 [00:14<00:18, 45.11it/s]Loading weights:  48%|████▊     | 735/1524 [00:14<00:13, 59.00it/s]Loading weights:  50%|████▉     | 761/1524 [00:15<00:17, 43.98it/s]Loading weights:  50%|████▉     | 761/1524 [00:15<00:19, 39.54it/s]Loading weights:  52%|█████▏    | 785/1524 [00:15<00:12, 60.55it/s]Loading weights:  52%|█████▏    | 785/1524 [00:15<00:12, 59.25it/s]Loading weights:  47%|████▋     | 711/1524 [00:15<00:19, 40.89it/s]Loading weights:  47%|████▋     | 711/1524 [00:15<00:19, 40.89it/s]Loading weights:  48%|████▊     | 736/1524 [00:15<00:17, 45.74it/s]Loading weights:  49%|████▉     | 746/1524 [00:15<00:16, 46.06it/s]Loading weights:  48%|████▊     | 736/1524 [00:15<00:17, 44.94it/s]Loading weights:  48%|████▊     | 736/1524 [00:15<00:17, 44.90it/s]Loading weights:  48%|████▊     | 735/1524 [00:15<00:13, 56.65it/s]Loading weights:  48%|████▊     | 735/1524 [00:15<00:13, 56.65it/s]Loading weights:  52%|█████▏    | 797/1524 [00:15<00:15, 47.86it/s]Loading weights:  52%|█████▏    | 798/1524 [00:15<00:15, 46.45it/s]Loading weights:  50%|████▉     | 761/1524 [00:15<00:16, 45.65it/s]Loading weights:  50%|████▉     | 761/1524 [00:15<00:18, 40.47it/s]Loading weights:  49%|████▉     | 747/1524 [00:15<00:17, 44.57it/s]Loading weights:  49%|████▉     | 747/1524 [00:15<00:17, 44.56it/s]Loading weights:  50%|████▉     | 761/1524 [00:16<00:16, 45.04it/s]Loading weights:  50%|████▉     | 761/1524 [00:16<00:16, 45.06it/s]Loading weights:  53%|█████▎    | 811/1524 [00:16<00:16, 42.21it/s]Loading weights:  53%|█████▎    | 811/1524 [00:16<00:17, 40.37it/s]Loading weights:  55%|█████▍    | 835/1524 [00:16<00:11, 60.55it/s]Loading weights:  55%|█████▍    | 835/1524 [00:16<00:11, 59.96it/s]Loading weights:  50%|████▉     | 761/1524 [00:16<00:19, 38.47it/s]Loading weights:  50%|████▉     | 761/1524 [00:16<00:19, 38.47it/s]Loading weights:  52%|█████▏    | 786/1524 [00:16<00:16, 45.62it/s]Loading weights:  52%|█████▏    | 786/1524 [00:16<00:17, 42.24it/s]Loading weights:  52%|█████▏    | 786/1524 [00:16<00:16, 45.09it/s]Loading weights:  52%|█████▏    | 786/1524 [00:16<00:16, 45.07it/s]Loading weights:  53%|█████▎    | 810/1524 [00:16<00:12, 58.98it/s]Loading weights:  56%|█████▌    | 847/1524 [00:16<00:14, 45.65it/s]Loading weights:  56%|█████▌    | 847/1524 [00:16<00:15, 44.82it/s]Loading weights:  53%|█████▎    | 811/1524 [00:17<00:15, 45.65it/s]Loading weights:  53%|█████▎    | 811/1524 [00:17<00:16, 43.39it/s]Loading weights:  52%|█████▏    | 786/1524 [00:17<00:18, 40.50it/s]Loading weights:  52%|█████▏    | 786/1524 [00:17<00:18, 40.51it/s]Loading weights:  53%|█████▎    | 811/1524 [00:17<00:15, 45.17it/s]Loading weights:  55%|█████▍    | 835/1524 [00:17<00:11, 58.99it/s]Loading weights:  54%|█████▍    | 821/1524 [00:17<00:15, 46.76it/s]Loading weights:  56%|█████▋    | 861/1524 [00:17<00:16, 39.53it/s]Loading weights:  56%|█████▋    | 861/1524 [00:17<00:17, 38.87it/s]Loading weights:  55%|█████▍    | 836/1524 [00:17<00:15, 45.44it/s]Loading weights:  53%|█████▎    | 811/1524 [00:17<00:17, 41.65it/s]Loading weights:  53%|█████▎    | 811/1524 [00:17<00:17, 41.65it/s]Loading weights:  56%|█████▌    | 847/1524 [00:17<00:14, 46.37it/s]Loading weights:  55%|█████▍    | 836/1524 [00:17<00:15, 45.07it/s]Loading weights:  55%|█████▍    | 836/1524 [00:17<00:16, 40.84it/s]Loading weights:  58%|█████▊    | 886/1524 [00:17<00:14, 43.54it/s]Loading weights:  58%|█████▊    | 886/1524 [00:17<00:14, 43.16it/s]Loading weights:  60%|█████▉    | 910/1524 [00:17<00:10, 60.89it/s]Loading weights:  60%|█████▉    | 910/1524 [00:17<00:10, 61.00it/s]Loading weights:  56%|█████▋    | 861/1524 [00:18<00:14, 45.34it/s]Loading weights:  56%|█████▋    | 861/1524 [00:18<00:16, 39.80it/s]Loading weights:  55%|█████▍    | 836/1524 [00:18<00:16, 42.48it/s]Loading weights:  55%|█████▍    | 836/1524 [00:18<00:16, 42.48it/s]Loading weights:  56%|█████▋    | 861/1524 [00:18<00:14, 45.03it/s]Loading weights:  56%|█████▋    | 861/1524 [00:18<00:15, 42.24it/s]Loading weights:  56%|█████▋    | 860/1524 [00:18<00:11, 57.36it/s]Loading weights:  56%|█████▋    | 860/1524 [00:18<00:11, 57.35it/s]Loading weights:  60%|██████    | 922/1524 [00:18<00:12, 49.26it/s]Loading weights:  60%|██████    | 922/1524 [00:18<00:12, 49.09it/s]Loading weights:  58%|█████▊    | 886/1524 [00:18<00:14, 45.26it/s]Loading weights:  58%|█████▊    | 886/1524 [00:18<00:15, 41.64it/s]Loading weights:  58%|█████▊    | 886/1524 [00:18<00:14, 43.06it/s]Loading weights:  58%|█████▊    | 886/1524 [00:18<00:14, 44.95it/s]Loading weights:  57%|█████▋    | 871/1524 [00:18<00:14, 44.78it/s]Loading weights:  57%|█████▋    | 871/1524 [00:18<00:14, 44.78it/s]Loading weights:  60%|█████▉    | 910/1524 [00:18<00:10, 58.01it/s]Loading weights:  61%|██████▏   | 936/1524 [00:18<00:13, 42.84it/s]Loading weights:  61%|██████▏   | 936/1524 [00:18<00:13, 42.69it/s]Loading weights:  63%|██████▎   | 960/1524 [00:18<00:09, 62.26it/s]Loading weights:  63%|██████▎   | 960/1524 [00:18<00:09, 62.23it/s]Loading weights:  60%|█████▉    | 911/1524 [00:19<00:13, 45.28it/s]Loading weights:  60%|██████    | 922/1524 [00:19<00:13, 45.59it/s]Loading weights:  58%|█████▊    | 886/1524 [00:19<00:16, 39.25it/s]Loading weights:  58%|█████▊    | 886/1524 [00:19<00:16, 39.25it/s]Loading weights:  60%|█████▉    | 911/1524 [00:19<00:13, 44.87it/s]Loading weights:  60%|█████▉    | 911/1524 [00:19<00:14, 43.58it/s]Loading weights:  64%|██████▍   | 973/1524 [00:19<00:11, 47.32it/s]Loading weights:  64%|██████▍   | 973/1524 [00:19<00:11, 47.38it/s]Loading weights:  61%|██████▏   | 935/1524 [00:19<00:10, 58.77it/s]Loading weights:  61%|██████▏   | 935/1524 [00:19<00:10, 58.35it/s]Loading weights:  61%|██████▏   | 936/1524 [00:19<00:13, 45.14it/s]Loading weights:  61%|██████▏   | 936/1524 [00:19<00:15, 39.08it/s]Loading weights:  60%|█████▉    | 911/1524 [00:19<00:14, 40.91it/s]Loading weights:  60%|█████▉    | 911/1524 [00:19<00:14, 40.91it/s]Loading weights:  65%|██████▍   | 986/1524 [00:19<00:13, 38.80it/s]Loading weights:  65%|██████▍   | 986/1524 [00:19<00:13, 38.75it/s]Loading weights:  62%|██████▏   | 946/1524 [00:19<00:12, 46.41it/s]Loading weights:  62%|██████▏   | 946/1524 [00:19<00:12, 45.69it/s]Loading weights:  66%|██████▋   | 1010/1524 [00:20<00:08, 57.54it/s]Loading weights:  66%|██████▋   | 1010/1524 [00:20<00:08, 57.52it/s]Loading weights:  63%|██████▎   | 961/1524 [00:20<00:12, 45.24it/s]Loading weights:  63%|██████▎   | 961/1524 [00:20<00:13, 41.32it/s]Loading weights:  61%|██████▏   | 936/1524 [00:20<00:13, 42.03it/s]Loading weights:  61%|██████▏   | 936/1524 [00:20<00:13, 42.03it/s]Loading weights:  63%|██████▎   | 961/1524 [00:20<00:13, 40.53it/s]Loading weights:  63%|██████▎   | 961/1524 [00:20<00:14, 39.92it/s]Loading weights:  65%|██████▍   | 985/1524 [00:20<00:09, 57.87it/s]Loading weights:  67%|██████▋   | 1022/1524 [00:20<00:10, 46.37it/s]Loading weights:  67%|██████▋   | 1022/1524 [00:20<00:10, 46.38it/s]Loading weights:  65%|██████▍   | 986/1524 [00:20<00:11, 45.23it/s]Loading weights:  65%|██████▌   | 997/1524 [00:20<00:11, 45.39it/s]Loading weights:  68%|██████▊   | 1036/1524 [00:21<00:12, 38.70it/s]Loading weights:  68%|██████▊   | 1036/1524 [00:21<00:12, 38.73it/s]Loading weights:  63%|██████▎   | 961/1524 [00:21<00:13, 42.77it/s]Loading weights:  63%|██████▎   | 961/1524 [00:21<00:13, 42.77it/s]Loading weights:  65%|██████▍   | 986/1524 [00:21<00:12, 42.03it/s]Loading weights:  65%|██████▍   | 986/1524 [00:21<00:12, 41.65it/s]Loading weights:  66%|██████▋   | 1011/1524 [00:21<00:13, 38.98it/s]Loading weights:  66%|██████▋   | 1011/1524 [00:21<00:11, 45.15it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:21<00:11, 41.23it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:21<00:11, 41.22it/s]Loading weights:  66%|██████▋   | 1011/1524 [00:21<00:11, 42.92it/s]Loading weights:  66%|██████▋   | 1011/1524 [00:21<00:12, 42.68it/s]Loading weights:  68%|██████▊   | 1035/1524 [00:21<00:08, 56.99it/s]Loading weights:  65%|██████▍   | 986/1524 [00:21<00:12, 43.21it/s]Loading weights:  65%|██████▍   | 986/1524 [00:21<00:12, 43.21it/s]Loading weights:  71%|███████   | 1085/1524 [00:21<00:07, 58.35it/s]Loading weights:  71%|███████   | 1085/1524 [00:21<00:07, 58.34it/s]Loading weights:  68%|██████▊   | 1035/1524 [00:21<00:08, 58.10it/s]Loading weights:  68%|██████▊   | 1035/1524 [00:21<00:08, 58.01it/s]Loading weights:  68%|██████▊   | 1036/1524 [00:22<00:10, 45.12it/s]Loading weights:  69%|██████▊   | 1047/1524 [00:22<00:10, 44.20it/s]Loading weights:  72%|███████▏  | 1097/1524 [00:22<00:08, 47.69it/s]Loading weights:  72%|███████▏  | 1097/1524 [00:22<00:08, 47.66it/s]Loading weights:  66%|██████▋   | 1011/1524 [00:22<00:11, 43.54it/s]Loading weights:  66%|██████▋   | 1011/1524 [00:22<00:11, 43.54it/s]Loading weights:  69%|██████▊   | 1046/1524 [00:22<00:10, 45.07it/s]Loading weights:  69%|██████▊   | 1047/1524 [00:22<00:10, 45.64it/s]Loading weights:  68%|██████▊   | 1035/1524 [00:22<00:08, 57.79it/s]Loading weights:  68%|██████▊   | 1035/1524 [00:22<00:08, 57.79it/s]Loading weights:  73%|███████▎  | 1111/1524 [00:22<00:09, 42.17it/s]Loading weights:  73%|███████▎  | 1111/1524 [00:22<00:09, 42.17it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:22<00:09, 46.54it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:22<00:11, 39.67it/s]Loading weights:  71%|███████   | 1085/1524 [00:22<00:07, 58.81it/s]Loading weights:  74%|███████▍  | 1135/1524 [00:22<00:06, 61.30it/s]Loading weights:  74%|███████▍  | 1135/1524 [00:22<00:06, 61.31it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:22<00:11, 39.52it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:22<00:11, 39.21it/s]Loading weights:  69%|██████▊   | 1046/1524 [00:22<00:10, 45.09it/s]Loading weights:  69%|██████▊   | 1046/1524 [00:22<00:10, 45.08it/s]Loading weights:  71%|███████▏  | 1086/1524 [00:23<00:09, 46.17it/s]Loading weights:  75%|███████▌  | 1147/1524 [00:23<00:07, 47.64it/s]Loading weights:  75%|███████▌  | 1147/1524 [00:23<00:07, 47.63it/s]Loading weights:  72%|███████▏  | 1098/1524 [00:23<00:09, 45.55it/s]Loading weights:  71%|███████▏  | 1086/1524 [00:23<00:10, 41.35it/s]Loading weights:  71%|███████▏  | 1086/1524 [00:23<00:10, 41.16it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:23<00:11, 39.71it/s]Loading weights:  70%|██████▉   | 1061/1524 [00:23<00:11, 39.71it/s]Loading weights:  73%|███████▎  | 1110/1524 [00:23<00:07, 57.50it/s]Loading weights:  73%|███████▎  | 1110/1524 [00:23<00:07, 57.29it/s]Loading weights:  76%|███████▌  | 1161/1524 [00:23<00:09, 39.69it/s]Loading weights:  76%|███████▌  | 1161/1524 [00:23<00:09, 39.68it/s]Loading weights:  73%|███████▎  | 1111/1524 [00:23<00:08, 46.09it/s]Loading weights:  73%|███████▎  | 1111/1524 [00:23<00:10, 38.45it/s]Loading weights:  78%|███████▊  | 1185/1524 [00:23<00:05, 59.00it/s]Loading weights:  74%|███████▍  | 1135/1524 [00:23<00:06, 57.61it/s]Loading weights:  71%|███████▏  | 1086/1524 [00:23<00:10, 41.23it/s]Loading weights:  71%|███████▏  | 1086/1524 [00:23<00:10, 41.23it/s]Loading weights:  74%|███████▎  | 1122/1524 [00:23<00:08, 45.16it/s]Loading weights:  74%|███████▎  | 1122/1524 [00:23<00:08, 44.98it/s]Loading weights:  78%|███████▊  | 1186/1524 [00:24<00:07, 43.56it/s]Loading weights:  79%|███████▊  | 1198/1524 [00:24<00:06, 47.98it/s]Loading weights:  75%|███████▍  | 1136/1524 [00:24<00:08, 46.13it/s]Loading weights:  79%|███████▉  | 1210/1524 [00:24<00:05, 61.34it/s]Loading weights:  75%|███████▌  | 1148/1524 [00:24<00:08, 45.26it/s]Loading weights:  75%|███████▍  | 1136/1524 [00:24<00:09, 38.91it/s]Loading weights:  75%|███████▍  | 1136/1524 [00:24<00:09, 38.95it/s]Loading weights:  73%|███████▎  | 1111/1524 [00:24<00:09, 42.20it/s]Loading weights:  73%|███████▎  | 1111/1524 [00:24<00:09, 42.21it/s]Loading weights:  76%|███████▌  | 1160/1524 [00:24<00:06, 56.80it/s]Loading weights:  76%|███████▌  | 1160/1524 [00:24<00:06, 56.78it/s]Loading weights:  79%|███████▉  | 1211/1524 [00:24<00:07, 39.25it/s]Loading weights:  80%|████████  | 1222/1524 [00:24<00:06, 46.65it/s]Loading weights:  76%|███████▌  | 1161/1524 [00:24<00:07, 45.85it/s]Loading weights:  76%|███████▌  | 1161/1524 [00:24<00:09, 38.02it/s]Loading weights:  81%|████████  | 1235/1524 [00:24<00:04, 58.43it/s]Loading weights:  78%|███████▊  | 1185/1524 [00:24<00:05, 57.18it/s]Loading weights:  77%|███████▋  | 1172/1524 [00:24<00:08, 43.99it/s]Loading weights:  75%|███████▍  | 1136/1524 [00:24<00:09, 42.94it/s]Loading weights:  75%|███████▍  | 1136/1524 [00:24<00:09, 42.94it/s]Loading weights:  77%|███████▋  | 1173/1524 [00:24<00:07, 44.65it/s]Loading weights:  81%|████████  | 1236/1524 [00:25<00:07, 40.91it/s]Loading weights:  82%|████████▏ | 1247/1524 [00:25<00:05, 46.42it/s]Loading weights:  83%|████████▎ | 1260/1524 [00:25<00:04, 59.64it/s]Loading weights:  78%|███████▊  | 1186/1524 [00:25<00:07, 45.65it/s]Loading weights:  79%|███████▊  | 1198/1524 [00:25<00:07, 44.52it/s]Loading weights:  78%|███████▊  | 1186/1524 [00:25<00:08, 37.58it/s]Loading weights:  78%|███████▊  | 1186/1524 [00:25<00:08, 37.74it/s]Loading weights:  76%|███████▌  | 1161/1524 [00:25<00:08, 43.37it/s]Loading weights:  76%|███████▌  | 1161/1524 [00:25<00:08, 43.37it/s]Loading weights:  78%|███████▊  | 1185/1524 [00:25<00:05, 57.81it/s]Loading weights:  83%|████████▎ | 1261/1524 [00:25<00:06, 40.84it/s]Loading weights:  83%|████████▎ | 1272/1524 [00:25<00:05, 47.74it/s]Loading weights:  79%|███████▉  | 1211/1524 [00:25<00:06, 45.57it/s]Loading weights:  79%|███████▉  | 1211/1524 [00:25<00:08, 37.69it/s]Loading weights:  81%|████████  | 1235/1524 [00:25<00:04, 59.66it/s]Loading weights:  81%|████████  | 1235/1524 [00:25<00:05, 56.78it/s]Loading weights:  79%|███████▉  | 1211/1524 [00:26<00:07, 40.22it/s]Loading weights:  79%|███████▉  | 1211/1524 [00:26<00:07, 40.11it/s]Loading weights:  78%|███████▊  | 1186/1524 [00:26<00:07, 43.61it/s]Loading weights:  78%|███████▊  | 1196/1524 [00:26<00:07, 45.23it/s]Loading weights:  81%|████████  | 1235/1524 [00:26<00:05, 57.01it/s]Loading weights:  84%|████████▍ | 1286/1524 [00:26<00:05, 41.83it/s]Loading weights:  84%|████████▍ | 1286/1524 [00:26<00:05, 44.37it/s]Loading weights:  86%|████████▌ | 1310/1524 [00:26<00:03, 62.50it/s]Loading weights:  86%|████████▌ | 1310/1524 [00:26<00:03, 61.68it/s]Loading weights:  82%|████████▏ | 1246/1524 [00:26<00:05, 46.79it/s]Loading weights:  82%|████████▏ | 1248/1524 [00:26<00:06, 44.16it/s]Loading weights:  81%|████████  | 1236/1524 [00:26<00:06, 41.65it/s]Loading weights:  82%|████████▏ | 1247/1524 [00:26<00:06, 44.54it/s]Loading weights:  79%|███████▉  | 1211/1524 [00:26<00:07, 43.71it/s]Loading weights:  79%|███████▉  | 1211/1524 [00:26<00:07, 39.53it/s]Loading weights:  87%|████████▋ | 1322/1524 [00:26<00:04, 49.60it/s]Loading weights:  87%|████████▋ | 1323/1524 [00:26<00:04, 49.15it/s]Loading weights:  83%|████████▎ | 1260/1524 [00:26<00:04, 57.44it/s]Loading weights:  83%|████████▎ | 1261/1524 [00:26<00:06, 40.93it/s]Loading weights:  83%|████████▎ | 1261/1524 [00:26<00:07, 37.34it/s]Loading weights:  84%|████████▍ | 1285/1524 [00:27<00:04, 56.31it/s]Loading weights:  83%|████████▎ | 1261/1524 [00:27<00:06, 38.38it/s]Loading weights:  88%|████████▊ | 1336/1524 [00:27<00:04, 41.55it/s]Loading weights:  88%|████████▊ | 1336/1524 [00:27<00:04, 40.42it/s]Loading weights:  83%|████████▎ | 1272/1524 [00:27<00:05, 45.33it/s]Loading weights:  81%|████████  | 1236/1524 [00:27<00:06, 43.77it/s]Loading weights:  81%|████████  | 1236/1524 [00:27<00:07, 41.04it/s]Loading weights:  84%|████████▍ | 1285/1524 [00:27<00:04, 56.45it/s]Loading weights:  89%|████████▉ | 1360/1524 [00:27<00:02, 60.60it/s]Loading weights:  89%|████████▉ | 1360/1524 [00:27<00:02, 60.12it/s]Loading weights:  84%|████████▍ | 1286/1524 [00:27<00:05, 42.27it/s]Loading weights:  85%|████████▌ | 1298/1524 [00:27<00:05, 44.00it/s]Loading weights:  84%|████████▍ | 1286/1524 [00:27<00:06, 38.98it/s]Loading weights:  90%|█████████ | 1372/1524 [00:27<00:03, 48.39it/s]Loading weights:  90%|█████████ | 1373/1524 [00:27<00:03, 48.55it/s]Loading weights:  85%|████████▌ | 1298/1524 [00:27<00:05, 44.40it/s]Loading weights:  83%|████████▎ | 1261/1524 [00:27<00:05, 44.02it/s]Loading weights:  83%|████████▎ | 1261/1524 [00:27<00:06, 42.19it/s]Loading weights:  86%|████████▌ | 1311/1524 [00:28<00:04, 43.37it/s]Loading weights:  86%|████████▌ | 1311/1524 [00:28<00:05, 37.47it/s]Loading weights:  88%|████████▊ | 1335/1524 [00:28<00:03, 56.36it/s]Loading weights:  91%|█████████ | 1386/1524 [00:28<00:03, 41.59it/s]Loading weights:  91%|█████████ | 1386/1524 [00:28<00:03, 42.17it/s]Loading weights:  93%|█████████▎| 1410/1524 [00:28<00:01, 61.81it/s]Loading weights:  93%|█████████▎| 1410/1524 [00:28<00:01, 62.12it/s]Loading weights:  86%|████████▌ | 1311/1524 [00:28<00:05, 40.91it/s]Loading weights:  86%|████████▌ | 1311/1524 [00:28<00:05, 37.40it/s]Loading weights:  84%|████████▍ | 1286/1524 [00:28<00:05, 44.05it/s]Loading weights:  84%|████████▍ | 1286/1524 [00:28<00:05, 42.82it/s]Loading weights:  88%|████████▊ | 1335/1524 [00:28<00:03, 55.89it/s]Loading weights:  86%|████████▌ | 1310/1524 [00:28<00:03, 57.94it/s]Loading weights:  86%|████████▌ | 1310/1524 [00:28<00:03, 57.55it/s]Loading weights:  88%|████████▊ | 1336/1524 [00:28<00:04, 44.02it/s]Loading weights:  88%|████████▊ | 1348/1524 [00:28<00:03, 44.34it/s]Loading weights:  93%|█████████▎| 1423/1524 [00:28<00:02, 49.33it/s]Loading weights:  93%|█████████▎| 1423/1524 [00:28<00:02, 49.60it/s]Loading weights:  88%|████████▊ | 1336/1524 [00:28<00:04, 42.31it/s]Loading weights:  88%|████████▊ | 1348/1524 [00:28<00:03, 44.10it/s]Loading weights:  87%|████████▋ | 1321/1524 [00:28<00:04, 44.90it/s]Loading weights:  87%|████████▋ | 1321/1524 [00:28<00:04, 45.58it/s]Loading weights:  89%|████████▉ | 1361/1524 [00:29<00:03, 44.36it/s]Loading weights:  89%|████████▉ | 1361/1524 [00:29<00:04, 37.47it/s]Loading weights:  94%|█████████▍| 1436/1524 [00:29<00:02, 40.81it/s]Loading weights:  94%|█████████▍| 1436/1524 [00:29<00:02, 41.01it/s]Loading weights:  96%|█████████▌| 1460/1524 [00:29<00:01, 61.14it/s]Loading weights:  96%|█████████▌| 1460/1524 [00:29<00:01, 61.00it/s]Loading weights:  89%|████████▉ | 1361/1524 [00:29<00:03, 43.29it/s]Loading weights:  89%|████████▉ | 1361/1524 [00:29<00:04, 37.46it/s]Loading weights:  88%|████████▊ | 1336/1524 [00:29<00:04, 39.95it/s]Loading weights:  88%|████████▊ | 1336/1524 [00:29<00:04, 39.37it/s]Loading weights:  91%|█████████ | 1386/1524 [00:29<00:03, 40.44it/s]Loading weights:  91%|█████████ | 1386/1524 [00:29<00:03, 44.76it/s]Loading weights:  93%|█████████▎| 1410/1524 [00:29<00:01, 57.65it/s]Loading weights:  97%|█████████▋| 1473/1524 [00:29<00:01, 46.37it/s]Loading weights:  97%|█████████▋| 1473/1524 [00:29<00:01, 46.28it/s]Loading weights:  91%|█████████ | 1386/1524 [00:29<00:03, 43.89it/s]Loading weights:  91%|█████████ | 1386/1524 [00:29<00:03, 40.26it/s]Loading weights:  92%|█████████▏| 1406/1524 [00:30<00:02, 53.94it/s]Loading weights:  89%|████████▉ | 1361/1524 [00:30<00:03, 41.45it/s]Loading weights:  89%|████████▉ | 1361/1524 [00:30<00:03, 41.09it/s]Loading weights:  91%|█████████ | 1385/1524 [00:30<00:02, 57.16it/s]Loading weights:  93%|█████████▎| 1411/1524 [00:30<00:02, 45.00it/s]Loading weights:  98%|█████████▊| 1486/1524 [00:30<00:00, 40.52it/s]Loading weights:  98%|█████████▊| 1486/1524 [00:30<00:00, 40.37it/s]Loading weights:  93%|█████████▎| 1422/1524 [00:30<00:02, 45.11it/s]Loading weights:  99%|█████████▉| 1510/1524 [00:30<00:00, 60.51it/s]Loading weights:  93%|█████████▎| 1411/1524 [00:30<00:02, 44.33it/s]Loading weights:  93%|█████████▎| 1417/1524 [00:30<00:02, 42.19it/s]Loading weights:  91%|█████████ | 1386/1524 [00:30<00:03, 42.00it/s]Loading weights:  92%|█████████▏| 1397/1524 [00:30<00:02, 44.77it/s]Loading weights:  93%|█████████▎| 1410/1524 [00:30<00:01, 57.20it/s]Loading weights:  94%|█████████▍| 1436/1524 [00:30<00:01, 46.46it/s]Loading weights:  94%|█████████▍| 1436/1524 [00:30<00:02, 40.32it/s]Loading weights:  99%|█████████▉| 1511/1524 [00:30<00:00, 42.84it/s]Loading weights:  96%|█████████▌| 1460/1524 [00:30<00:01, 59.18it/s]Loading weights: 100%|██████████| 1524/1524 [00:30<00:00, 49.35it/s]
Model init total -- 37.03s
Loading weights: 100%|█████████▉| 1523/1524 [00:30<00:00, 44.96it/s]Loading weights: 100%|██████████| 1524/1524 [00:30<00:00, 49.35it/s]
Model init total -- 37.03s
Loading weights:  94%|█████████▍| 1436/1524 [00:31<00:01, 44.68it/s]Loading weights:  94%|█████████▍| 1436/1524 [00:31<00:02, 40.34it/s]Loading weights:  93%|█████████▎| 1411/1524 [00:31<00:02, 38.42it/s]Loading weights:  93%|█████████▎| 1422/1524 [00:31<00:02, 45.13it/s]Loading weights:  96%|█████████▌| 1461/1524 [00:31<00:01, 46.16it/s]Loading weights:  97%|█████████▋| 1473/1524 [00:31<00:01, 45.94it/s]Loading weights:  96%|█████████▌| 1461/1524 [00:31<00:01, 44.76it/s]Loading weights:  96%|█████████▌| 1461/1524 [00:31<00:01, 41.98it/s]Loading weights:  97%|█████████▋| 1485/1524 [00:31<00:00, 58.99it/s]Loading weights:  94%|█████████▍| 1436/1524 [00:31<00:02, 40.67it/s]Loading weights:  94%|█████████▍| 1436/1524 [00:31<00:02, 39.01it/s]Loading weights:  98%|█████████▊| 1486/1524 [00:31<00:00, 46.08it/s]Loading weights:  98%|█████████▊| 1486/1524 [00:31<00:00, 38.71it/s]Loading weights:  99%|█████████▉| 1506/1524 [00:31<00:00, 53.92it/s]Loading weights:  98%|█████████▊| 1486/1524 [00:32<00:00, 43.08it/s]Loading weights:  98%|█████████▊| 1496/1524 [00:32<00:00, 46.50it/s]Loading weights:  99%|█████████▉| 1510/1524 [00:32<00:00, 58.75it/s]Loading weights:  96%|█████████▌| 1461/1524 [00:32<00:01, 41.97it/s]Loading weights:  96%|█████████▌| 1461/1524 [00:32<00:01, 40.93it/s]Loading weights:  99%|█████████▉| 1511/1524 [00:32<00:00, 47.28it/s]Loading weights: 100%|█████████▉| 1518/1524 [00:32<00:00, 44.05it/s]Loading weights:  97%|█████████▋| 1485/1524 [00:32<00:00, 57.00it/s]Loading weights:  97%|█████████▋| 1485/1524 [00:32<00:00, 57.33it/s]Loading weights: 100%|██████████| 1524/1524 [00:32<00:00, 46.99it/s]
Model init total -- 38.58s
Loading weights: 100%|██████████| 1524/1524 [00:32<00:00, 46.98it/s]
Model init total -- 38.59s
Loading weights:  99%|█████████▉| 1511/1524 [00:32<00:00, 40.77it/s]Loading weights: 100%|█████████▉| 1521/1524 [00:32<00:00, 45.39it/s]Loading weights: 100%|██████████| 1524/1524 [00:32<00:00, 46.45it/s]
Model init total -- 38.96s
Loading weights: 100%|██████████| 1524/1524 [00:32<00:00, 46.45it/s]
Model init total -- 38.96s
Loading weights:  98%|█████████▊| 1496/1524 [00:32<00:00, 44.59it/s]Loading weights:  98%|█████████▊| 1497/1524 [00:32<00:00, 44.79it/s]2025-03-28 05:45:51,422 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:51,436 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:51] [TRT-LLM] [E] Failed to initialize executor on rank 1: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:51] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

2025-03-28 05:45:51,506 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:51,519 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:51] [TRT-LLM] [E] Failed to initialize executor on rank 5: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:51] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

Loading weights:  99%|█████████▉| 1511/1524 [00:33<00:00, 39.33it/s]Loading weights:  99%|█████████▉| 1511/1524 [00:33<00:00, 38.69it/s]Loading weights: 100%|██████████| 1524/1524 [00:33<00:00, 45.44it/s]
Loading weights: 100%|██████████| 1524/1524 [00:33<00:00, 45.44it/s]
Model init total -- 39.69s
Model init total -- 39.69s
2025-03-28 05:45:52,963 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:52,979 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:52] [TRT-LLM] [E] Failed to initialize executor on rank 6: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:52] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

2025-03-28 05:45:53,120 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:53,135 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:53] [TRT-LLM] [E] Failed to initialize executor on rank 2: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:53] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

2025-03-28 05:45:53,327 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:53,339 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:53] [TRT-LLM] [E] Failed to initialize executor on rank 3: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:53] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

2025-03-28 05:45:53,458 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:53,471 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:53] [TRT-LLM] [E] Failed to initialize executor on rank 7: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:53] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

2025-03-28 05:45:54,058 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:54,071 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:54] [TRT-LLM] [E] Failed to initialize executor on rank 4: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:54] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

2025-03-28 05:45:54,208 - INFO - flashinfer.jit: Loading JIT ops: norm
2025-03-28 05:45:54,220 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[03/28/2025-05:45:54] [TRT-LLM] [E] Failed to initialize executor on rank 0: N must be a multiple of 128, (N=2112)
[03/28/2025-05:45:54] [TRT-LLM] [E] Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 612, in worker_main
    worker: ExecutorBindingsWorker = worker_cls(
                                     ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 118, in __init__
    self.engine = _create_engine()
                  ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/worker.py", line 114, in _create_engine
    return create_executor(executor_config=executor_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/py_executor_creator.py", line 116, in create_py_executor
    kv_cache_max_tokens = estimate_max_kv_cache_tokens(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/_util.py", line 144, in estimate_max_kv_cache_tokens
    model_engine.forward(req, resource_manager)
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1541, in forward
    return self._forward_step(inputs, gather_ids)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/pyexecutor/model_engine.py", line 1618, in _forward_step
    logits = self.model.forward(**inputs,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 909, in forward
    hidden_states = self.model(
                    ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 772, in forward
    hidden_states, residual = decoder_layer(position_ids=position_ids,
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/models/modeling_deepseekv3.py", line 491, in forward
    hidden_states = self.self_attn(
                    ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/attention.py", line 437, in forward
    compressed_q, compressed_kv, k_pe = self.fused_a(
                                        ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1740, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1751, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 409, in forward
    output = self.apply_linear(input, self.weight, self.bias)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/modules/linear.py", line 330, in apply_linear
    output = torch.ops.trtllm.fp8_block_scaling_gemm(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1123, in __call__
    return self._op(*args, **(kwargs or {}))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: N must be a multiple of 128, (N=2112)

Traceback (most recent call last):
  File "/usr/local/bin/trtllm-bench", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/click/decorators.py", line 45, in new_func
    return f(get_current_context().obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/bench/benchmark/throughput.py", line 268, in throughput_command
    llm = PyTorchLLM(**kwargs)
          ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/_torch/llm.py", line 27, in __init__
    super().__init__(model, tokenizer, tokenizer_mode, skip_tokenizer_init,
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/llmapi/llm.py", line 166, in __init__
    raise e
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/llmapi/llm.py", line 161, in __init__
    self._build_model()
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/llmapi/llm.py", line 561, in _build_model
    self._executor = self._executor_cls.create(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/executor.py", line 364, in create
    return ExecutorBindingsProxy(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/proxy.py", line 91, in __init__
    self._start_executor_workers(worker_kwargs)
  File "/usr/local/lib/python3.12/dist-packages/tensorrt_llm/executor/proxy.py", line 289, in _start_executor_workers
    raise ready_signal
RuntimeError: N must be a multiple of 128, (N=2112)
